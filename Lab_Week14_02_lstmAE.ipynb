{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a href=\"https://colab.research.google.com/github/Panperception/TutorialDL/blob/main/Lab_Week14_02_lstmAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"CMryP5VppfhE"},"source":["## LSTM AE"]},{"cell_type":"markdown","metadata":{"id":"MOouYS9IG5uv"},"source":["This notebook demonstrates how train a LSTM Autoencoder on the MNIST dataset.\n","\n","### Your task\n","1.   Learn and summarize LSTM AE with respect to: Architecture, Cost Funstion, Latent Space, Reparameterization, etc..\n","2.   Try to change the dataset to MNISt Denoising and Face-Sketch datasets\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IO2wYhysp6Nc"},"source":["## Load Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OnZLE7b8LA6q","vscode":{"languageId":"python"}},"outputs":[],"source":["from keras.datasets import mnist\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","(x_train, y_train), (x_test, y_train) = mnist.load_data()\n","\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","x_train = np.reshape(x_train, (len(x_train), 28,28, 1))\n","x_test = np.reshape(x_test, (len(x_test), 28,28, 1))\n","print(x_train.shape)\n","print(x_test.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"vO_U8btxp9I0"},"source":["## Define LSTM AE Model"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1322,"status":"ok","timestamp":1644336532739,"user":{"displayName":"Deep Perception","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQOCW6zkh1X1hylIK0ktIx1YpiXHevNKSdLkZJ=s64","userId":"15861160368812880821"},"user_tz":0},"id":"5b0MelFfzGHk","vscode":{"languageId":"python"}},"outputs":[],"source":["import keras\n","from keras import layers\n","\n","timesteps = 28  # Length of your sequences\n","input_dim = 28\n","latent_dim = 32\n","\n","inputs = keras.Input(shape=(timesteps, input_dim))\n","encoded = layers.LSTM(latent_dim)(inputs)\n","\n","decoded = layers.RepeatVector(timesteps)(encoded)\n","decoded = layers.LSTM(input_dim, return_sequences=True)(decoded)\n","\n","model_lstmAE = keras.Model(inputs, decoded)\n","model_lstmAE_encoder = keras.Model(inputs, encoded)"]},{"cell_type":"markdown","metadata":{"id":"ZPURsh-CzUjX"},"source":["## Training and Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9mnqvkuzehg","vscode":{"languageId":"python"}},"outputs":[],"source":["from keras.callbacks import TensorBoard\n","\n","model_lstmAE.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","model_lstmAE.fit(x_train, x_train,\n","                epochs=50,\n","                batch_size=128,\n","                shuffle=True,\n","                validation_data=(x_test, x_test),\n","                callbacks=[TensorBoard(log_dir='/tmp/model_convAE')])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-V9O1djwRW6Y","vscode":{"languageId":"python"}},"outputs":[],"source":["plt.plot(model_lstmAE.history.history[\"loss\"])\n","plt.plot(model_lstmAE.history.history[\"val_loss\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P2zpj4jXzfj8","vscode":{"languageId":"python"}},"outputs":[],"source":["decoded_imgs = model_lstmAE.predict(x_test)\n","\n","n = 10\n","plt.figure(figsize=(20, 4))\n","for i in range(1, n + 1):\n","    # Display original\n","    ax = plt.subplot(2, n, i)\n","    plt.imshow(x_test[i].reshape(28, 28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","\n","    # Display reconstruction\n","    ax = plt.subplot(2, n, i + n)\n","    plt.imshow(decoded_imgs[i])\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ce5ust38zt1G","vscode":{"languageId":"python"}},"outputs":[],"source":["encoded_imgs = model_lstmAE_encoder.predict(x_test)\n","\n","n = 10\n","plt.figure(figsize=(20, 8))\n","for i in range(1, n + 1):\n","    ax = plt.subplot(1, n, i)\n","    plt.imshow(encoded_imgs[i].reshape(8, 4))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOJhhx030YDYW1m/r9PO8p8","collapsed_sections":[],"history_visible":true,"name":"Lab2022_Week14_02_lstmAE.ipynb","provenance":[{"file_id":"1CuaPNZ2V3y8mIqAc5CtLwuexL0T2EMHq","timestamp":1612913030190},{"file_id":"1wCuTWZ97gBQmeEhkBn64E8neu_SdVxRj","timestamp":1612905236869}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
